{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook for Google Colab\n",
    "\n",
    "My main code for this project is in [aneurysm_detection.ipynb](aneurysm_detection.ipynb). For organization and simplification purposes, the code for running my models on a Google Colab GPU environment is all here: this mainly involves loading the generated data. The generated data was created from the preprocessing code in [aneurysm_detection.ipynb](aneurysm_detection.ipynb)"
   ],
   "id": "304f785d4bd1883f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from pydicom import dcmread\n",
    "from pydicom.data import get_testdata_file\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Dropout, GlobalAveragePooling2D, BatchNormalization, Activation\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.metrics import BinaryAccuracy, Precision, Recall\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras_tuner import Hyperband\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "import time\n",
    "import cv2\n",
    "import gc\n",
    "import plotly.express as px\n",
    "import sys"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "home_folder = '/content/drive/My Drive/Colab Notebooks/rsna-intercranial-aneurysm-detection/'\n",
    "data_gen_folder = home_folder + 'data_gen_2/'"
   ],
   "id": "a3fb42593862994f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_val_file_path = data_gen_folder + 'X_val.pkl'\n",
    "X_train_file_path = data_gen_folder + 'X_train.pkl'\n",
    "y_val_file_path = data_gen_folder + 'y_val.csv'\n",
    "y_train_file_path = data_gen_folder + 'y_train.csv'"
   ],
   "id": "d36d6ede833698e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_val_loaded = pd.read_csv(y_val_file_path)\n",
    "y_train_loaded = pd.read_csv(y_train_file_path)\n",
    "\n",
    "y_val_loaded = np.array(y_val_loaded)\n",
    "y_train_loaded = np.array(y_train_loaded)\n",
    "\n",
    "y_val_in_brain = y_val_loaded[:, 0]\n",
    "y_val_visible = y_val_loaded[:, 1]\n",
    "y_train_in_brain = y_train_loaded[:, 0]\n",
    "y_train_visible = y_train_loaded[:, 1]"
   ],
   "id": "d0c417f08ce5d476"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(X_val_file_path, 'rb') as file:\n",
    "    X_val_loaded = pickle.load(file)"
   ],
   "id": "325d6d28807c2d07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(X_train_file_path, 'rb') as file:\n",
    "    X_train_loaded = pickle.load(file)"
   ],
   "id": "55f87d68edb45440"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_loaded = X_train_loaded[..., np.newaxis]\n",
    "X_val_loaded = X_val_loaded[..., np.newaxis]"
   ],
   "id": "91b32b24f73fa07a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_history_file_path = data_gen_folder + 'training_history.txt'\n",
    "model_save_file_path = data_gen_folder + 'saved_model.keras'"
   ],
   "id": "6eabb5bc072f94e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val_visible_ds = Dataset.from_tensor_slices((X_val_loaded, y_val_visible))\n",
    "train_visible_ds = Dataset.from_tensor_slices((X_train_loaded, y_train_visible))"
   ],
   "id": "3efb264e32eb84e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val_in_brain_ds = Dataset.from_tensor_slices((X_val_loaded, y_val_in_brain))\n",
    "train_in_brain_ds = Dataset.from_tensor_slices((X_train_loaded, y_train_in_brain))"
   ],
   "id": "5a534a9c88b643cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "del X_train_loaded\n",
    "del X_val_loaded\n",
    "gc.collect()"
   ],
   "id": "c62d310028060628"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "processed_image_dim = 512",
   "id": "abe598846e7728ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This model can be used *separately* for in_brain_with_aneurysm and aneurysm_visible_in_image\n",
    "# Different architectures may be better suited for each problem\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape=(processed_image_dim, processed_image_dim, 1))\n",
    "\n",
    "    # Vary the number of filters in conv layers\n",
    "    x = Conv2D(filters=hp.Int('conv1_filters', min_value=16, max_value=64, step=16),\n",
    "               kernel_size=hp.Choice('conv1_kernel', values=[3, 5]), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "\n",
    "    x = Conv2D(filters=hp.Int('conv2_filters', min_value=32, max_value=128, step=32),\n",
    "               kernel_size=hp.Choice('conv2_kernel', values=[3, 5]), activation='relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "\n",
    "    x = Conv2D(filters=hp.Int('conv3_filters', 64, 256, step=64), kernel_size=3, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Dropout(rate=hp.Float('dropout_1', 0.2, 0.4, step=0.1))(x)\n",
    "\n",
    "    x = Conv2D(256, 3, activation='relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "\n",
    "    x = Conv2D(256, 3, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(rate=hp.Float('dropout_2', 0.3, 0.5, step=0.1))(x)\n",
    "\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Choose between the two (seemingly) most popular optimizers and a variety of learning rates\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=hp.Float('adam_lr', 1e-5, 1e-3, sampling='log'))\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=hp.Float('rms_lr', 1e-5, 1e-3, sampling='log'))\n",
    "\n",
    "    model = keras.Model(inputs, out)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Recall(), keras.metrics.Precision()]\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "id": "ac7ad02561f7b4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tuner_results_folder = data_gen_folder + 'tuner_results'\n",
    "experiment_name = 'e1'\n",
    "\n",
    "tuner = Hyperband(\n",
    "    build_model,                          # your model-building function\n",
    "    objective='val_loss',                 # what to optimize\n",
    "    max_epochs=40,                        # maximum epochs for top models\n",
    "    factor=3,                             # reduction factor per bracket\n",
    "    hyperband_iterations=2,               # how many full Hyperband rounds\n",
    "    seed=42,\n",
    "    directory=tuner_results_folder,\n",
    "    project_name=experiment_name,\n",
    ")\n",
    "\n",
    "# Optional early stopping to save time\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "tuner.search(\n",
    "    train_in_brain_ds,\n",
    "    validation_data=val_in_brain_ds,\n",
    "    epochs=40,\n",
    "    callbacks=[stop_early],\n",
    ")"
   ],
   "id": "517746ee9cf6358"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
